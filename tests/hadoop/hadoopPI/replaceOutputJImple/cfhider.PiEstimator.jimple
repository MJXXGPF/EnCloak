public class cfhider.PiEstimator extends org.apache.hadoop.conf.Configured implements org.apache.hadoop.util.Tool
{
    private static final org.apache.hadoop.fs.Path TMP_DIR;

    public void <init>()
    {
        cfhider.PiEstimator r0;

        r0 := @this: cfhider.PiEstimator;
        specialinvoke r0.<org.apache.hadoop.conf.Configured: void <init>()>();
        return;
    }

    public static java.math.BigDecimal estimate(int, long, org.apache.hadoop.mapred.JobConf) throws java.io.IOException
    {
        int i0, i2;
        long l1, $l3, $l4, l5, $l6, $l7, $l8, $l9;
        org.apache.hadoop.mapred.JobConf r0;
        java.lang.Class $r1;
        org.apache.hadoop.fs.Path $r2, r3, r4, r6, $r17, $r18, $r19, $r21, $r42, r43, $r57, $r59;
        org.apache.hadoop.fs.FileSystem r5;
        org.apache.hadoop.io.LongWritable r7, r8, r12, $r26, $r27, $r44, r45, $r46;
        org.apache.hadoop.io.SequenceFile$CompressionType $r9;
        org.apache.hadoop.io.SequenceFile$Writer r10;
        java.lang.Throwable r11, r14, r15, $r28, $r48, $r58;
        org.apache.hadoop.io.SequenceFile$Reader r13, $r47;
        java.lang.String $r16, $r25, $r33, $r41;
        org.apache.hadoop.fs.Path[] $r20;
        java.lang.StringBuilder $r22, $r23, $r24, $r30, $r31, $r32, $r37, $r38, $r39, $r40;
        java.io.PrintStream $r29, $r34, $r36;
        double $d0, d1;
        java.math.BigDecimal $r49, $r50, $r51, $r52, $r53, $r54, $r55, r56;

        i0 := @parameter0: int;
        l1 := @parameter1: long;
        r0 := @parameter2: org.apache.hadoop.mapred.JobConf;
        $r1 = class "cfhider/PiEstimator";
        $r16 = virtualinvoke $r1.<java.lang.Class: java.lang.String getSimpleName()>();
        virtualinvoke r0.<org.apache.hadoop.mapred.JobConf: void setJobName(java.lang.String)>($r16);
        virtualinvoke r0.<org.apache.hadoop.mapred.JobConf: void setInputFormat(java.lang.Class)>(class "org/apache/hadoop/mapred/SequenceFileInputFormat");
        virtualinvoke r0.<org.apache.hadoop.mapred.JobConf: void setOutputKeyClass(java.lang.Class)>(class "org/apache/hadoop/io/BooleanWritable");
        virtualinvoke r0.<org.apache.hadoop.mapred.JobConf: void setOutputValueClass(java.lang.Class)>(class "org/apache/hadoop/io/LongWritable");
        virtualinvoke r0.<org.apache.hadoop.mapred.JobConf: void setOutputFormat(java.lang.Class)>(class "org/apache/hadoop/mapred/SequenceFileOutputFormat");
        virtualinvoke r0.<org.apache.hadoop.mapred.JobConf: void setMapperClass(java.lang.Class)>(class "cfhider/PiEstimator$PiMapper");
        virtualinvoke r0.<org.apache.hadoop.mapred.JobConf: void setNumMapTasks(int)>(i0);
        virtualinvoke r0.<org.apache.hadoop.mapred.JobConf: void setReducerClass(java.lang.Class)>(class "cfhider/PiEstimator$PiReducer");
        virtualinvoke r0.<org.apache.hadoop.mapred.JobConf: void setNumReduceTasks(int)>(1);
        virtualinvoke r0.<org.apache.hadoop.mapred.JobConf: void setSpeculativeExecution(boolean)>(0);
        $r17 = new org.apache.hadoop.fs.Path;
        $r2 = <cfhider.PiEstimator: org.apache.hadoop.fs.Path TMP_DIR>;
        specialinvoke $r17.<org.apache.hadoop.fs.Path: void <init>(org.apache.hadoop.fs.Path,java.lang.String)>($r2, "in");
        r3 = $r17;
        $r18 = new org.apache.hadoop.fs.Path;
        $r19 = <cfhider.PiEstimator: org.apache.hadoop.fs.Path TMP_DIR>;
        specialinvoke $r18.<org.apache.hadoop.fs.Path: void <init>(org.apache.hadoop.fs.Path,java.lang.String)>($r19, "out");
        r4 = $r18;
        $r20 = newarray (org.apache.hadoop.fs.Path)[1];
        $r20[0] = r3;
        staticinvoke <org.apache.hadoop.mapred.FileInputFormat: void setInputPaths(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path[])>(r0, $r20);
        staticinvoke <org.apache.hadoop.mapred.FileOutputFormat: void setOutputPath(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path)>(r0, r4);
        r5 = staticinvoke <org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem get(org.apache.hadoop.conf.Configuration)>(r0);

     label0:
        i2 = 0;

     label1:
        if i2 >= i0 goto label8;

        $r21 = new org.apache.hadoop.fs.Path;
        $r22 = new java.lang.StringBuilder;
        specialinvoke $r22.<java.lang.StringBuilder: void <init>()>();
        $r23 = virtualinvoke $r22.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("part");
        $r24 = virtualinvoke $r23.<java.lang.StringBuilder: java.lang.StringBuilder append(int)>(i2);
        $r25 = virtualinvoke $r24.<java.lang.StringBuilder: java.lang.String toString()>();
        specialinvoke $r21.<org.apache.hadoop.fs.Path: void <init>(org.apache.hadoop.fs.Path,java.lang.String)>(r3, $r25);
        r6 = $r21;
        $r26 = new org.apache.hadoop.io.LongWritable;
        $l3 = (long) i2;
        $l4 = $l3 * l1;
        specialinvoke $r26.<org.apache.hadoop.io.LongWritable: void <init>(long)>($l4);
        r7 = $r26;
        $r27 = new org.apache.hadoop.io.LongWritable;
        specialinvoke $r27.<org.apache.hadoop.io.LongWritable: void <init>(long)>(l1);
        r8 = $r27;
        $r9 = <org.apache.hadoop.io.SequenceFile$CompressionType: org.apache.hadoop.io.SequenceFile$CompressionType NONE>;
        r10 = staticinvoke <org.apache.hadoop.io.SequenceFile: org.apache.hadoop.io.SequenceFile$Writer createWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.Class,java.lang.Class,org.apache.hadoop.io.SequenceFile$CompressionType)>(r5, r0, r6, class "org/apache/hadoop/io/LongWritable", class "org/apache/hadoop/io/LongWritable", $r9);

     label2:
        virtualinvoke r10.<org.apache.hadoop.io.SequenceFile$Writer: void append(org.apache.hadoop.io.Writable,org.apache.hadoop.io.Writable)>(r7, r8);

     label3:
        virtualinvoke r10.<org.apache.hadoop.io.SequenceFile$Writer: void close()>();
        goto label7;

     label4:
        $r28 := @caughtexception;

     label5:
        r11 = $r28;

     label6:
        virtualinvoke r10.<org.apache.hadoop.io.SequenceFile$Writer: void close()>();
        throw r11;

     label7:
        $r29 = <java.lang.System: java.io.PrintStream out>;
        $r30 = new java.lang.StringBuilder;
        specialinvoke $r30.<java.lang.StringBuilder: void <init>()>();
        $r31 = virtualinvoke $r30.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Wrote input for Map #");
        $r32 = virtualinvoke $r31.<java.lang.StringBuilder: java.lang.StringBuilder append(int)>(i2);
        $r33 = virtualinvoke $r32.<java.lang.StringBuilder: java.lang.String toString()>();
        virtualinvoke $r29.<java.io.PrintStream: void println(java.lang.String)>($r33);
        i2 = i2 + 1;
        goto label1;

     label8:
        $r34 = <java.lang.System: java.io.PrintStream out>;
        virtualinvoke $r34.<java.io.PrintStream: void println(java.lang.String)>("Starting Job");
        l5 = staticinvoke <java.lang.System: long currentTimeMillis()>();
        staticinvoke <org.apache.hadoop.mapred.JobClient: org.apache.hadoop.mapred.RunningJob runJob(org.apache.hadoop.mapred.JobConf)>(r0);
        $l6 = staticinvoke <java.lang.System: long currentTimeMillis()>();
        $l7 = $l6 - l5;
        $d0 = (double) $l7;
        d1 = $d0 / 1000.0;
        $r36 = <java.lang.System: java.io.PrintStream out>;
        $r37 = new java.lang.StringBuilder;
        specialinvoke $r37.<java.lang.StringBuilder: void <init>()>();
        $r38 = virtualinvoke $r37.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Job Finished in ");
        $r39 = virtualinvoke $r38.<java.lang.StringBuilder: java.lang.StringBuilder append(double)>(d1);
        $r40 = virtualinvoke $r39.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" seconds");
        $r41 = virtualinvoke $r40.<java.lang.StringBuilder: java.lang.String toString()>();
        virtualinvoke $r36.<java.io.PrintStream: void println(java.lang.String)>($r41);
        $r42 = new org.apache.hadoop.fs.Path;
        specialinvoke $r42.<org.apache.hadoop.fs.Path: void <init>(org.apache.hadoop.fs.Path,java.lang.String)>(r4, "reduce-out");
        r43 = $r42;
        $r44 = new org.apache.hadoop.io.LongWritable;
        specialinvoke $r44.<org.apache.hadoop.io.LongWritable: void <init>()>();
        r45 = $r44;
        $r46 = new org.apache.hadoop.io.LongWritable;
        specialinvoke $r46.<org.apache.hadoop.io.LongWritable: void <init>()>();
        r12 = $r46;
        $r47 = new org.apache.hadoop.io.SequenceFile$Reader;
        specialinvoke $r47.<org.apache.hadoop.io.SequenceFile$Reader: void <init>(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration)>(r5, r43, r0);
        r13 = $r47;

     label9:
        virtualinvoke r13.<org.apache.hadoop.io.SequenceFile$Reader: boolean next(org.apache.hadoop.io.Writable,org.apache.hadoop.io.Writable)>(r45, r12);

     label10:
        virtualinvoke r13.<org.apache.hadoop.io.SequenceFile$Reader: void close()>();
        goto label14;

     label11:
        $r48 := @caughtexception;

     label12:
        r14 = $r48;

     label13:
        virtualinvoke r13.<org.apache.hadoop.io.SequenceFile$Reader: void close()>();
        throw r14;

     label14:
        $r49 = staticinvoke <java.math.BigDecimal: java.math.BigDecimal valueOf(long)>(4L);
        $r50 = virtualinvoke $r49.<java.math.BigDecimal: java.math.BigDecimal setScale(int)>(20);
        $l8 = virtualinvoke r45.<org.apache.hadoop.io.LongWritable: long get()>();
        $r51 = staticinvoke <java.math.BigDecimal: java.math.BigDecimal valueOf(long)>($l8);
        $r52 = virtualinvoke $r50.<java.math.BigDecimal: java.math.BigDecimal multiply(java.math.BigDecimal)>($r51);
        $l9 = (long) i0;
        $r53 = staticinvoke <java.math.BigDecimal: java.math.BigDecimal valueOf(long)>($l9);
        $r54 = virtualinvoke $r52.<java.math.BigDecimal: java.math.BigDecimal divide(java.math.BigDecimal)>($r53);
        $r55 = staticinvoke <java.math.BigDecimal: java.math.BigDecimal valueOf(long)>(l1);
        r56 = virtualinvoke $r54.<java.math.BigDecimal: java.math.BigDecimal divide(java.math.BigDecimal)>($r55);

     label15:
        $r57 = <cfhider.PiEstimator: org.apache.hadoop.fs.Path TMP_DIR>;
        virtualinvoke r5.<org.apache.hadoop.fs.FileSystem: boolean delete(org.apache.hadoop.fs.Path,boolean)>($r57, 1);
        return r56;

     label16:
        $r58 := @caughtexception;

     label17:
        r15 = $r58;

     label18:
        $r59 = <cfhider.PiEstimator: org.apache.hadoop.fs.Path TMP_DIR>;
        virtualinvoke r5.<org.apache.hadoop.fs.FileSystem: boolean delete(org.apache.hadoop.fs.Path,boolean)>($r59, 1);
        throw r15;

        catch java.lang.Throwable from label2 to label3 with label4;
        catch java.lang.Throwable from label5 to label6 with label4;
        catch java.lang.Throwable from label9 to label10 with label11;
        catch java.lang.Throwable from label12 to label13 with label11;
        catch java.lang.Throwable from label0 to label15 with label16;
        catch java.lang.Throwable from label17 to label18 with label16;
    }

    public int run(java.lang.String[]) throws java.lang.Exception
    {
        cfhider.PiEstimator r0;
        java.lang.String[] r1;
        int i0, $i2;
        long l1;
        org.apache.hadoop.mapred.JobConf r2, $r14;
        java.io.PrintStream $r3, $r11, $r17, $r18;
        java.lang.StringBuilder $r4, $r5, $r8, $r9;
        java.lang.Class $r6, $r16;
        java.lang.String $r7, $r10, $r12, $r13;
        org.apache.hadoop.conf.Configuration $r15;
        java.math.BigDecimal $r19;

        r0 := @this: cfhider.PiEstimator;
        r1 := @parameter0: java.lang.String[];
        $i2 = lengthof r1;
        if $i2 == 2 goto label0;

        $r3 = <java.lang.System: java.io.PrintStream err>;
        $r4 = new java.lang.StringBuilder;
        specialinvoke $r4.<java.lang.StringBuilder: void <init>()>();
        $r5 = virtualinvoke $r4.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("Usage: ");
        $r6 = virtualinvoke r0.<java.lang.Object: java.lang.Class getClass()>();
        $r7 = virtualinvoke $r6.<java.lang.Class: java.lang.String getName()>();
        $r8 = virtualinvoke $r5.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>($r7);
        $r9 = virtualinvoke $r8.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>(" <nMaps> <nSamples>");
        $r10 = virtualinvoke $r9.<java.lang.StringBuilder: java.lang.String toString()>();
        virtualinvoke $r3.<java.io.PrintStream: void println(java.lang.String)>($r10);
        $r11 = <java.lang.System: java.io.PrintStream err>;
        staticinvoke <org.apache.hadoop.util.ToolRunner: void printGenericCommandUsage(java.io.PrintStream)>($r11);
        return -1;

     label0:
        $r12 = r1[0];
        i0 = staticinvoke <java.lang.Integer: int parseInt(java.lang.String)>($r12);
        $r13 = r1[1];
        l1 = staticinvoke <java.lang.Long: long parseLong(java.lang.String)>($r13);
        $r14 = new org.apache.hadoop.mapred.JobConf;
        $r15 = virtualinvoke r0.<cfhider.PiEstimator: org.apache.hadoop.conf.Configuration getConf()>();
        $r16 = virtualinvoke r0.<java.lang.Object: java.lang.Class getClass()>();
        specialinvoke $r14.<org.apache.hadoop.mapred.JobConf: void <init>(org.apache.hadoop.conf.Configuration,java.lang.Class)>($r15, $r16);
        r2 = $r14;
        $r17 = <java.lang.System: java.io.PrintStream out>;
        virtualinvoke $r17.<java.io.PrintStream: void println(java.lang.String)>("Estimated value of Pi is ");
        $r18 = <java.lang.System: java.io.PrintStream out>;
        $r19 = staticinvoke <cfhider.PiEstimator: java.math.BigDecimal estimate(int,long,org.apache.hadoop.mapred.JobConf)>(i0, l1, r2);
        virtualinvoke $r18.<java.io.PrintStream: void println(java.lang.Object)>($r19);
        return 0;
    }

    public static void main(java.lang.String[]) throws java.lang.Exception
    {
        java.lang.String[] r0;
        cfhider.PiEstimator $r1;
        int $i0;

        r0 := @parameter0: java.lang.String[];
        $r1 = new cfhider.PiEstimator;
        specialinvoke $r1.<cfhider.PiEstimator: void <init>()>();
        $i0 = staticinvoke <org.apache.hadoop.util.ToolRunner: int run(org.apache.hadoop.conf.Configuration,org.apache.hadoop.util.Tool,java.lang.String[])>(null, $r1, r0);
        staticinvoke <java.lang.System: void exit(int)>($i0);
        return;
    }

    static org.apache.hadoop.fs.Path access$000()
    {
        org.apache.hadoop.fs.Path $r0;

        $r0 = <cfhider.PiEstimator: org.apache.hadoop.fs.Path TMP_DIR>;
        return $r0;
    }

    static void <clinit>()
    {
        org.apache.hadoop.fs.Path $r0;
        java.lang.StringBuilder $r1, $r4, $r5;
        java.lang.Class $r2;
        java.lang.String $r3, $r6;

        $r0 = new org.apache.hadoop.fs.Path;
        $r1 = new java.lang.StringBuilder;
        specialinvoke $r1.<java.lang.StringBuilder: void <init>()>();
        $r2 = class "cfhider/PiEstimator";
        $r3 = virtualinvoke $r2.<java.lang.Class: java.lang.String getSimpleName()>();
        $r4 = virtualinvoke $r1.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>($r3);
        $r5 = virtualinvoke $r4.<java.lang.StringBuilder: java.lang.StringBuilder append(java.lang.String)>("_TMP_3_141592654");
        $r6 = virtualinvoke $r5.<java.lang.StringBuilder: java.lang.String toString()>();
        specialinvoke $r0.<org.apache.hadoop.fs.Path: void <init>(java.lang.String)>($r6);
        <cfhider.PiEstimator: org.apache.hadoop.fs.Path TMP_DIR> = $r0;
        return;
    }
}
